by susantha bathige  read comments 8  related tips more  replication free webcast  simplify sql server administration problem i have several clustered sql server 2012 instances installed and i am having issues with replication latency the environment has a dedicated sql server instance for the distributor one instance has publisher database s and another instance has subscriber database s it is reported that there is high latency in replication most of the time i also noticed that there is a lot of blocking on the distribution server with big cpu spikes solution fixing latency issues is not a straightforward process you need to gather a lot of data analyze the data make changes one at a time and then monitor to see if you have fixed the issue this is a continuous process until you get acceptable latency understanding data flow in sql server transactional replication before we begin it will help to understand the data flow of sql server transactional replication there are three main components publisher  the databaseserver which needs to replicate data distributor  the databaseserver which stores the replicated data temporarily subscriber  the destination databaseserver which consumes the replicated data typically in a high use oltp system each component is a dedicated sql server to support high availability figure 1 shows the architecture of transactional replication figure 1  replication architecture bol httpmsdnmicrosoftcomenuslibraryms151176aspxmonitoring sql server transactional replication it is necessary to implement a latency report to monitor and alert if latency is above a certain threshold that you define it could be 5 minutes 10 minutes or even a few seconds depending on your environment and service level agreement sla with the users this is really important when troubleshooting latency issues the latency report should have information about the total latency latency between publisher and distributor latency between distributor and subscriber therefore you will know exactly which part of replication has issues tracer tokens are commonly used to measure latency you can use replication monitor rm to insert a tracer token for each publication alternatively you could use tsql commands as well fore more details about tracer tokens refer to this bol httptechnetmicrosoftcomenuslibraryms151846 vsql105aspx how to get replication latency the following is output from spreplcounters for a good performing environmentdatabase replicated transactions replication rate transsec replication latency sec replbeginlsn replnextlsn publisherdb1 2587 1946951 004 0x0008c11a00316d090001 0x0008c11a00316d090004publisherdb1 0 5625 1883 0x00000000000000000000 0x00000000000000000000table 1  sample output of spreplcounters database  publisher database replicated transactions  number of transactions in the log awaiting delivery to the distribution database replication rate transsec  average number of transactions per second delivered to the distribution database replication latency  average time in seconds that transactions were in the log before being distributed replbeginlsn  log sequence number lsn of the current truncation point in the log replendlsn  lsn of the next commit record awaiting delivery to the distribution database using the above information you can determine how good the overall replication latency is the higher the value you see in replication transactions ratesec the better the data transfer speed for replication also having low numbers for the replication latency sec column sample output of poorly performing replication system is shown in table 2database replicated transactions replication rate transsec replication latency sec replbeginlsn replnextlsn publisherdb1 11170556 1612123 9232216 0x000998c5006a0e6c0021 0x000998c5006a1c720004table 2  output of spreplcounter against poorly performing replication system in this situation you can see latency is over 25 hours refer replication latency column 9232 seconds at the same time you can see the data transfer rate is fairly good 1612123 so what may be the problem see the replicated transactions it is more than 11 million meaning there are over 11 million commands waiting to be delivered to the distribution database in other words they are still in the transaction log tlog of the publisher database so in this particular case the latency is mainly between the publisher and the distributor if you configured the latency report it would show a high value of latency between the publisher and distributor if you see strange high figures like above table 2 this could be due to following reasonslarge transactions occurred in publisher databaseslow performing networkslow performing storage if you see millions of waiting commands in the output and you figured it is not due to a slow network slow storage or unexpected oltp operations at the publisher then the issue is probably with the configuration of tlog of the publisher database remember replication is one of the log based operations in sql server so the configuration of the tlog for the publisher database closely relates to the performance of replication the program called log reader scans the tlog to identify the commands to be replicated refer figure 1 so in this case you need to pay attention to the tlog size whether it is properly sized according to the transaction volume of the publisher the number of vlfs of the tlog and the size of vlfs for replication all these parameters matter it is quite challenging to identify the sweet spot of the tlog in terms of number of vlfs the below links might be helpfulhttpwwwmssqltipscomsqlservertip1225howtodeterminesqlserverdatabasetransactionlogusagehttpwwwsqlskillscomblogskimberlytransactionlogvlfstoomanyortoofewsql server log reader agent log reader is an executable which executes from the distributor and scans the tlog of the publisher database there are two threads that do the work reader thread  reads the tlog via the stored procedure spreplcmds this scans the tlog and identifies the commands to be replicated by skipping nottobe replicated commands writer thread  writes the transactions identified by the reader thread into the distribution database via spmsaddreplcmds both of these stored procedures are system stored procedures that are created when you configure transactional replication there are parameters for the log reader agent profile which you can use to change the behavior of the log reader thus you can change replication behavior taking a closer look at parameter values for the log reader is an essential part of troubleshooting replication issues including latency fore more details bol httpmsdnmicrosoftcomenuslibraryms146878aspx how to view log reader agent profile in ssms connect to the distribution server right click on replication and click on properties refer figure 2 and 3figure 2  get distributor properties figure 3  distributor properties click on profile defaults in the distributor properties window shown in figure 3 the agent profiles window displays as shown in figure 4 figure 4  agent profiles the right pane of the agent profiles window has all the replication agent profiles select log reader agents from the list and you will see the profiles for the log reader the ticked one is currently be used and you can click on â€¦ to get the configuration values for the log reader agent profile as shown in figure 5 below figure 5  profile parameters note when you change the log reader properties they will not take effect until you restart sql server agent important parameters of log reader agent profile there are certain parameters that you need to adjust as part of fine tuning process of transactional replication systemcontinuous  specifies whether the agent tries to poll replicated transactions continually if specified the agent polls replicated transactions from the source at polling intervals even if there are no transactions pendinghistory verbose level  0 1 2  specifies the amount of history logged during a log reader operation you can minimize the performance effect of history logging by selecting 1max cmds in tran  specifies the maximum number of statements grouped into a transaction as the log reader writes commands to the distribution database using this parameter allows the log reader agent and distribution agent to divide large transactions consisting of many commands at the publisher into several smaller transactions when applied at the subscriber specifying this parameter can reduce contention at the distributor and reduce latency between the publisher and subscriber because the original transaction is applied in smaller units the subscriber can access rows of a large logical publisher transaction prior to the end of the original transaction breaking strict transactional atomicity the default is 0 which preserves the transaction boundaries of the publisherpolling interval  is how often in seconds the log is queried for replicated transactions the default is 5 secondsread batch size  is the maximum number of transactions read out of the transaction log of the publishing database per processing cycle with a default of 500 the agent will continue to read transactions in batches until all transactions are read from the log this parameter is not supported for oracle publishersread batch threshold  is the number of replication commands to be read from the transaction log before being issued to the subscriber by the distribution agent the default is 0 if this parameter is not specified the log reader agent will read to the end of the log or to the number specified in read batch size number of transactions how to decide the log reader agent profile settings you can query the mslogreaderhistory table in the distribution database to see the log reader statistics by analyzing these data you can determine the performance of the log reader you can use the below queryuse distribution go select time cast comments as xml as comments runstatus duration xactseqno deliveredtransactions deliveredcommands averagecommands deliverytime deliveryrate deliverylatency   1000  60  as deliverylatencymin from mslogreaderhistory with nolock where time  20141028 160000130 order by time descit is difficult to attach a sample output because the output is very wide however i would like to highlight some of the columns look at the values in the comments column below it contains xml segments which have valuable information the comments column gives you information about how the log reader is performing the below table shows six different sample records of actual data in a replication environment look at rows 2 3 and 6 it displays more information with state 1 2 and 3 messages if you see a lot of messages like  approximately 2500000 log records have been scanned in pass  4 0 of which were marked for replication  which means the log reader agent has found 0 records to replicate this essentially means there are many operations going on in publisher which are not marked for replication increasing the read batch size parameter would be beneficial in this type of situation the default value of the parameter is 500 but you could increase this value by several thousand to scan more tlog records because most of the time you do not find much data to replicate seq comments1 12 transaction s with 14 command s were delivered2 no replicated transactions are available3 raised events that occur when an agents reader thread waits longer than the agents messageinterval time by default the time is 60 seconds if you notice state 2 events that are recorded for an agent this indicates that the agent is taking a long time to write changes to the destination4 raised events that are generated only by the log reader agent when the writer thread waits longer than the messageinterval time if you notice state 3 events that are recorded for the log reader agent this indicates that the agent is taking a long time to scan the replicated changes from the transaction log5 approximately 2500000 log records have been scanned in pass  4 0 of which were marked for replication6 normal events that describe both the reader and writer thread performanceltmessagesee below for what these state values meanstate 1  normal activity nothing to worry aboutstate 2  reader thread has to wait for writer thread has some issuesstate 3  writer thread has to wait for reader thread has some issues using these messages you can nail down your analysis of log reader agent performance to reader or writer thread issues another important data column you need to know is  xactseqno  which is the last processed transaction sequence number look at that value and see it is changing frequently if so replicated commands are processing quickly sometimes you may see the same value in xactseqno column for a long time maybe even for a few hours that indicates a large transaction occurred in the publisher database which resulted in large dml activities you can identify the actual commands of the transaction using the below code snippet use distribution go exec spbrowsereplcmds xactseqnostart  0x0008bf0f008a6d7f00aa xactseqnoend  0x0008bf0f008a6d7f00aa publisherdatabaseid  10publisherdatabaseid may be different than the database id of the publisher server you need to know that first before executing the above code use the below code to identify the publisherdatabaseid use distribution go select  from dbo mspublisherdatabases or use distribution go select top 1 publisherdatabaseid from msreplcommands where xactseqno  0x0008bf0f008a6d7f00aanote this publisher database id is different from the database id of sysdatabases in publisher server refer to the command column of spbrowsereplcmds query to see the actual command executing this way you can get a better sense of what is happening at the moment when there is a slowness in replication if the transaction has millions of dml activities it takes time to run the spbrowsereplcmds query additionally you can filter the records using articleid or commandid or both as belowuse distribution go exec spbrowsereplcmds xactseqnostart  0x0008bf0f008a6d7f00aa xactseqnoend  0x0008bf0f008a6d7f00aa publisherdatabaseid  10 articleid  1335 commandid 1000000how large are the replication specific tables the distribution database has many tables to support sql server replication it is important to know how big they are at least the most important ones this should be a part of your troubleshooting effort i normally use the below query to see the record count of the most centric tables for transactional replication use distribution go select getdate  as capture time objectname tobjectid as table name strowcount s name from sysdmdbpartitionstats st with nolock inner join systables t with nolock on stobjectid  tobjectid inner join sysschemas s with nolock on tschemaid  sschemaid where indexid  2 and objectname tobjectid in mssubscriptions msdistributionhistory msreplcommands msrepltransactions  order by strowcount desctable name description mssubscriptions contains one row for each published article in a subscription msdistributionhistory contains history rows for the distribution agents associated with the local distributor msreplcommands contains rows of replicated commands msrepltransactions contains one row for each replicated transaction if you see high rowcount probably more than 1 or 2 million this means there is some problem in replication it could be one of the reasons stated below cleanup job this is in distribution server is not running its taking lot of time to deliver the commands to subscriber there may be blocking in distribution server due to cleanup job use the below query to identify what is going on currently in the distribution server you can use the same query in any server for the same purposeselect rsessionid sprogramname sloginname rstarttime rstatus rcommand objectname sqltxtobjectid sqltxtdbid as object name substring sqltxttext  rstatementstartoffset  2   1   case rstatementendoffset when 1 then datalength sqltxttext else rstatementendoffset end  rstatementstartoffset   2   1 as activestatement rpercentcomplete dbname rdatabaseid as database name rblockingsessionid rwaittime rwaittype rwaitresource ropentransactioncount rcputime in milli sec rreads rwrites rlogicalreads rrowcount rpreverror rgrantedquerymemory cast sqlplanqueryplan as xml as query plan case rtransactionisolationlevel when 0 then unspecified when 1 then read uncomitted when 2 then read committed when 3 then repeatable when 4 then serializable when 5 then snapshot end as issolationlevel rsqlhandle rplanhandle from sysdmexecrequests r with nolock inner join sysdmexecsessions s with nolock on rsessionid  ssessionid cross apply sys dmexecsqltext rsqlhandle sqltxt cross apply sys dmexectextqueryplan rplanhandle rstatementstartoffset rstatementendoffset sqlplan where rstatus  background order by rsessionid go if you see blocking with lckms waits this is probably due to the cleanup job this job runs every 10 minutes and it clears the commands that have already been replicated it is safe to stop and disable the job for a couple of hours to clear the blocking most often i noticed the root blocker is spmssubscriptioncleanup this is a nested stored procedure call from spmsdistributioncleanup which is the distribution clean up job you also can notice the above stored procedure in cxpacket wait type and it blocks the following statement update msdistributionhistory set runstatus  runstatus time  currenttime duration  duration comments  comments xactseqno  xactseqno updateablerow  thisrowupdateable errorid  case errorid when 0 then errorid else errorid end where agentid  agentid and timestamp  lastrowtimestamp and  runstatus  runstatus or  updateexistingrow  1 and runstatus in  idle inprogress  and runstatus in  idle inprogress   the wait type for the above statement is lckmx and the wait resource is msdistributionhistory table this table is used inside the head blocker stored procedure and it already acquired the shared lock on most of the rows i feel ms needs some optimization to this code when i compared the cleanup job stored procedure between 2008 and 2012 versions of sql server i noticed it doubled the lines of code in the 2012 version at the same time you also may notice high cpu in distribution server and that is due to many blockings due to the above head blocker there is really nothing you can do except stop and disable the cleanup job for some time you also may try setting the maxdop to 1 in distribution server to bring down the cpu usage improving the latency between distributor and subscriber again thanks to the latency report if you identify the replication latency is between the distributor and subscriber then it is worth considering the below points publishing stored procedure execution this is especially useful in cases where large batch operations eg  delete are performed on the publisher i have seen cases where millions of rows are affected due to a large batch delete and the moment they occurred it started to transfer the commands to the distributor and then the subscriber this slows replication and you can notice increased latency using this method the same large batch operation execute at the subscriber instead of passing individual commands via the distributor however before implementing this solution you need to spend time doing some research and assess how feasible this is for your environment there are many factors that you need to be aware of for more detail httpmsdnmicrosoftcomenuslibraryms152754aspx enable multiple streams for subscriber enabling multiple streams for the subscriber can greatly improve aggregate transactional replication throughput by applying the subscriber changes in parallel still there are many factors you need to consider and you need to do some homework before getting this to production for more details httptechnetmicrosoftcomenuslibraryms151762 vsql105aspx maintain indexes and statistics in distribution database distribution database is categorized as a system database in ssms however some level of dba intervention is needed to keep the distribution database in good shape distribution database has tables indexes and statistics like normal user databases we know for a fact that indexes need to be maintained rebuildreorganize as well as running update statistics in user databases so why not the same operations in the distribution database the cleanup stored procedures has its own statistics update statements to keep the statistics up to date but not for all of them it is totally fine to have index and statistics update jobs deployed to the distribution database and schedule them to run at offpeak time as you do in user databases i have done this in production environments as per ms suggestion distribution agent performance you can query msdistributionhistory table to see how distribution agent performs use distribution go select top 100 time cast comments as xml as comments runstatus duration xactseqno deliveredcommands averagecommands currentdeliveryrate deliveredtransactions errorid deliverylatency from msdistributionhistory with nolock order by time descthe output of the above query is similar to the output of the log reader history table look at the value of the comments column if you see messages with state 1 which means distribution agent is performing normally using xactseqno you can identify the commands replicated if you notice the same value for xactseqno for a longer time which means it is replicating a large transaction distribution agent profile like the log reader agent profile there is a distribution agent profile on the distribution server if you open agent profiles window refer figure 4 from the right pane you can select distribution agents to see the profiles you can tweak the parameter values of the agent to change the replication behavior you can do it at the publication level or apply to all publications it will need a sql server agent restart in distribution server to take effect below are some parameters you may consider tweakingcommit batch size  is the number of transactions to be issued to the subscriber before a commit statement is issued the default is 100commit batch threshold  is the number of replication commands to be issued to the subscriber before a commit statement is issued the default is 1000history verbose level  0  1  2  3   specifies the amount of history logged during a distribution operation you can minimize the performance effect of history logging by selecting 1max delivered transactions  is the maximum number of push or pull transactions applied to subscribers in one synchronization a value of 0 indicates that the maximum is an infinite number of transactions other values can be used by subscribers to shorten the duration of a synchronization being pulled from a publisherpolling interval  is how often in seconds the distribution database is queried for replicated transactions the default is 5 secondssubscription streams 01264  is the number of connections allowed per distribution agent to apply batches of changes in parallel to a subscriber while maintaining many of the transactional characteristics present when using a single thread for a sql server publisher a range of values from 1 to 64 is supported this parameter is only supported when the publisher and distributor are running on sql server 2005 or later versions this parameter is not supported or must be 0 for nonsql server subscribers or peertopeer subscriptions for more details bol httpmsdnmicrosoftcomenuslibraryms147328aspx next steps still you see issues such as high cpu in distributor continuous blocking in distribution server increased latency even after working on the suggested changes in this article you probably require more analysis and maybe need to open a case with microsoft for further analysis see this link it has instructionsscripts to gather more data check out all of the sql server replication tips last update 20150417about the author susantha bathige currently works at pearson north america as a production dba he has over ten years of experience in sql server as a database engineer developer analyst and production dba view all my tips related resources more sql server dba tips tweet become a paid author 