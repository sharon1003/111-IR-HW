what is calibration how is calibration performed why is calibration important where are calibrations performed when are calibrations performed who performs calibrations what is calibration the word “calibration” has different meanings depending on the industry or setting in which it is used in the test and measurement industry calibration has a specific meaning which at a basic level is the act of comparing a device under test dut of an unknown value with a reference standard of a known value a person typically performs a calibration to determine the error or verify the accuracy of the dut’s unknown value as a basic example you could perform a calibration by measuring the temperature of a dut thermometer in water at the known boiling point 212 degrees fahrenheit to learn the error of the thermometer because visually determining the exact moment that boiling point is achieved can be imprecise you could achieve a more accurate result by placing a calibrated reference thermometer of a precise known value into the water to verify the dut thermometer a logical next step that can occur in a calibration process may be to adjust or true up the instrument to reduce measurement error technically adjustment is a separate step from calibration for a more formal definition of calibration we turn to the bipm bureau international des poids et mesures or international bureau of weights and measures wwwbipmorg  based in france which is the coordinator of the worldwide measurement system and is tasked with ensuring worldwide unification of measurements bipm produces a list of definitions for important technical terms commonly used in measurement and calibration this list referred to as the vim international vocabulary of metrology defines the meaning of calibration as an “operation that under specified conditions in a first step establishes a relation between the quantity values with measurement uncertainties provided by measurement standards and corresponding indications with associated measurement uncertainties and in a second step uses this information to establish a relation for obtaining a measurement result from an indication” this definition builds upon the basic definition of calibration by clarifying that the measurement standards used in calibration must be of known uncertainty amount of possible error in other words the known value must have a clearly understood uncertainty to help the instrument owner or user determine if the measurement uncertainty is appropriate for the calibration international system of units si – the top level of known measurement standards how do we arrive at measurement standards of known values against which we calibrate our devices under test for the answer we turn to the international system of units abbreviated “si” which is derived from “le système international dunités” in french the si consists of seven base units which are the second meter kilogram ampere kelvin mole and candela the seven base si units are mostly derived by quantities in nature that do not change such as the speed of light the kilogram is the exception where it is still defined by a cylindrical metallic alloy artifact known as the international prototype of the kilogram ipk or “le grand k” it is carefully and securely stored under double glass enclosure in a vault in paris it is anticipated that the definition of a kilogram will soon change from an artifact to be based on the plank constant it is interesting to note that the definition of some si units has improved over time for example consider the historical changes to the definition of one second1874  1956 1 86400 of a day1956  1967 the fraction 1 315569259747 of the tropical epoch year of 1900 based on astronomical observations between 1750 and 18921967  1997 the duration of 9192631770 periods of the radiation corresponding to the two hyperfine levels of cesium cs 1331997  1999 added at rest approaching 0 k1999  present included corrections for ambient radiation using the latest definition the second is realized by the weighted average of atomic clocks all around the world at this point it should be pointed out that the base si units can be combined per algebraic relations to form derivative units of measure important in calibration such as pressure pounds per square inch or psi in this case pressure is derived from the meter and kilogram base si units the si was created by resolution of the general conference on weights and measures cgpm an intergovernmental organization created via the treaty of the meter or convention of the metre signed in 1875 in paris the treaty of the meter also created organizations to help the cgpm namely the international committee for weights and measures cipm which discusses examines and compiles reports on the si for review by the cgpm and the bipm whose mission we mentioned above you can find and review cgpm resolutions at the bipm website today member states of the cgpm include all major industrialized countries calibration interoperability a key benefit of having the bipm manage the si on a worldwide basis is calibration interoperability this means that all around the world we are using the same measurement system and definitions this allows someone in the u s to purchase a 1 ohm resistor in australia and be confident that it will be 1 ohm as measured by u s standards and vice versa in order to have interoperability we need to have all of our measurements traceable to the same definition the calibration traceability pyramid – getting the si into industry now that we have the si reference standards how do we efficiently and economically share them with the world the calibration traceability pyramid think of the si at the top of a calibration pyramid where the bipm helps pass the si down to all levels of use within countries for the fostering of scientific discovery and innovation as well as industrial manufacturing and international trade just below the si level the bipm works directly with the national metrology institutes nmis of member states or countries to facilitate the promotion of the si within those countries the nmi of the united states is the national institute of standards and technology nist a nonregulated federal agency of the united states department of commerce fluke calibration works with nmis around the world where it does business you can see a list of nmis and other metrology organizations by country at the bipms nmi page because it’s not affordable efficient or even possible for everybody within a country to work directly with their nmi nmilevel calibration standards are used to calibrate primary calibration standards or instruments primary standards are then used to calibrate secondary standards secondary standards are used to calibrate working standards and working standards are used to calibrate process instruments in this way references to the si standards can be efficiently and affordably passed down the calibration pyramid through the nmi into industry as needed in some rare instances an si unit can be realized directly by a laboratory using a special instrument that implements physics to achieve the measurement the quantum hall ohm is an example of this type of device while it is directly used in several calibration laboratories in the united states the nmi is still involved by helping ensure the device is measuring correctly calibration traceability the lineage from the lowest level of the calibration pyramid all the way up to the si standards can be referred to as “traceability” an important calibration concept stated another way traceability or traceable calibration means that the calibration was performed with calibrated reference standards that are traceable through an unbroken chain back to the pertinent si unit through an nmi calibration traceability may also be thought of as the pedigree of the calibration traceability is also important in test and measurement because many technical and quality industry standards require measurement devices to be traceable for example traceable measurements are required in the medical device pharmaceutical aerospace military and defense industries as well as in many other manufacturing industries and traceable calibration always helps to improve process control and research by ensuring measurements and resulting data are correct as with other topics associated with calibration many technical requirements have been developed for managing and ensuring calibration traceability to mention a few requirements consideration must be given to calibration uncertainty calibration interval when does the calibration expire  and methods used to ensure that traceability stays intact in the calibration program for more information regarding traceability and other important metrology concepts visit fluke calibration’s general calibration  metrology topics technical library and metrology training pages calibration accreditation when calibrations are performed it’s important to be able to trust the process by which they are performed calibration accreditation provides that trust accreditation gives an instrument owner confidence that the calibration has been done correctly calibration accreditation means that a calibration process has been reviewed and found to be compliant with internationally accepted technical and quality metrology requirements isoiec 17025 is the international metrology quality standard to which calibration laboratories are accredited accreditation services are provided by independent organizations that have been certified to do this type of work every large country typically has at least one accreditation provider for example in the united states the national voluntary laboratory accreditation program nvlap a2la and lab are accreditation providers in england the united kingdom accreditation service ukas is the accreditation provider international agreements ensure that once a calibration process is accredited in one country any calibrations coming from that process can be accepted worldwide without any additional technical acceptance requirements calibration certificates a calibration laboratory often provides a certificate with the calibration of an instrument the calibration certificate provides important information to give the instrument’s owner confidence that the device was calibrated correctly and to help show proof of the calibration a calibration certificate might include a statement of traceability or a list of the calibration standards used for the calibration any data resulting from the calibration the calibration date and possibly pass or fail statements for each measurement result calibration certificates vary because not all calibration laboratories follow the same industry standards and they also can vary depending on where the calibration fits within the calibration pyramid or hierarchy for example the calibration certificate required for a grocery store scale may be very simple while the calibration certificate for a precision balance in a calibration laboratory may have a lot more technical content calibration certificates coming from an accredited calibration process have some very particular requirements which can be found in the international standard isoiec 17025 calibration uncertainty from the definition of calibration previously discussed you’ve probably noticed that “uncertainty” amount of possible error rather than accuracy is used to describe the capability of the calibration processes and outcomes in the test and measurement industry accuracy is often used to describe the measurement capability of an instrument often the instrument manufacturer intends for an accuracy specification to represent the expected range of error that may occur when using the instrument however the vim provides guidelines that uncertainty is the preferred term to use for describing the measurement specification of an instrument since uncertainty is the chosen vernacular to discuss amount of error and is such an important concept in the calibration discussion it deserves a bit more attention let’s start with a basic definition uncertainty describes a range of values in which the true value can be found for example if a voltmeter has a measurement uncertainty of ± 01 v when measuring a voltage value that appears on the display as 100 v the true voltage value could be as low as 99 v or as high as 101 v if the 01 v uncertainty is stated to have 95  coverage we can have 95  confidence that 10v ± 01 v contains the true value fortunately most results tend to be toward the middle of the possible range because random uncertainties tend to follow the gaussian distribution or normal bell curve with this understanding of uncertainty in mind the calibration standard needs to be of sufficiently low uncertainty that the user has confidence in the calibration result the calibration standard should have lower uncertainty better accuracy than the device being calibrated for example it does not make sense to calibrate a precise micrometer using a measuring tape similarly it does not make sense to calibrate a highprecision precious metal scale by comparing it with a bathroom scale an important international metrology standard the gum guide to the expression of uncertainty measurement goes one step further with the importance of uncertainty with the following statement“when reporting the result of a measurement of a physical quantity it is obligatory that some quantitative indication of the quality of the result be given so that those who use it can assess its reliability ”essentially the gum states that a measurement without a known uncertainty value will have an unknown level of quality and reliability uncertainties can enter the calibration equation from various sources for example let’s look at calibrating a temperature probe uncertainties can be introduced by the reference thermometer and the calibration system adding uncertainties of components together is referred to as an uncertainty evaluation some evaluations use an estimate of uncertainty that can allow many different models of temperature probes to be used so long as they don’t exceed a budgeted value and are therefore called uncertainty budgets here is an example of why calibration uncertainty and measurement uncertainty are an important part of our daily lives a typical gasoline pump in the united states can pump gas with an uncertainty of about ± 2 teaspoons 0003 gallons per gallon nobody is going to be upset if they are short a couple of teaspoons of gasoline and the gas station may not lose much money by giving away two teaspoons of gasoline per gallon sold however if the uncertainty of the gasoline pump is ± 01 gallon you can imagine how inappropriate this level of uncertainty would be for this measurement you could be shorted a gallon of gas for every 10 gallons that you pump so the reason why uncertainty is so important in calibration and measurement is because it is needed to allow the owner of the instrument or the customer of the measurement to evaluate confidence in the instrument or the measurement it could be an interesting experiment to ask a gasoline station manager for an estimate of uncertainty for one of their gasoline pumpsfor several years the simple 4 to 1 tur test uncertainty ratio has been implemented in many calibration processes it basically says that an appropriate uncertainty relationship between the calibration standard and the dut should be at 4 to 1 meaning the uncertainty of the reference measurement is four times smaller than the uncertainty of the dut calibrators example of a calibrator in this case the fluke 5730a electrical calibrator a device that calibrates other equipment is sometimes referred to as a calibrator  a calibrator is different from other types of calibration standards because it has a builtin calibration standard as well as useful features that make it easier to calibrate instruments for example the electrical calibrator shown here has connectors to allow a user to connect a device under test easily and safely and buttons and menu options to help the user efficiently perform a calibration calibration software using calibration software with the calibrator allows a user to completely automate the calibration and calculate calibration uncertainty calibration software increases the efficiency of performing calibrations while reducing procedural errors and reducing sources of uncertainty there is also calibration asset management software available that manages calibration equipment inventory calibration disciplines there are many calibration disciplines each having different types of calibrators and calibration references to get an idea of the types of calibrators and instruments that are available see the wide array of fluke calibration calibrators and other calibration equipment  common calibration disciplines include but are not limited to electrical radio frequency rftemperature humidity pressure flow dimensional resources temperature calibration information  general temperature calibration information page by fluke calibration introduction on the iso guide to the expression of uncertainty in measurement gum  ondemand webinar by fluke chief metrologist jeff gust how is a calibration performed there are several ways to calibrate an instrument depending on the type of instrument and the chosen calibration scheme there are two general calibration schemes calibration by comparison with a source of known value an example of a source calibration scheme is measuring an ohm meter using a calibrated reference standard resistor the reference resistor provides sources a known value of the ohm the desired calibration parameter a more sophisticated calibration source like the resistor is a multifunction calibrator that can source known values of resistance voltage current and possibly other electrical parameters a resistance calibration can also be performed by measuring a resistor of unknown value not calibrated with both the dut instrument and a reference ohm meter the two measurements are compared to determine the error of the dut calibration by comparison of the dut measurement with the measurement from a calibrated reference standard a variant of the sourcebased calibration is calibrating the dut against a source of known natural value such as a chemical melt or freeze temperature of a material like pure water from this basic set of calibration schemes the calibration options expand with each measurement discipline calibration steps a calibration process starts with the basic step of comparing a known with an unknown to determine the error or value of the unknown quantity however in practice a calibration process may consist of as found verification adjustment and as left verification many measurement devices are adjusted physically turning an adjust screw on a pressure gauge electrically turning a potentiometer in a volt meter or through internal firmware settings in a digital instrument nonadjustable instruments sometimes referred to as “artifacts” such as temperature rtds resistors and zener diodes are often calibrated by characterization calibration by characterization usually involves some type of mathematical relationship that allows the user to use the instrument to get calibrated values the mathematical relationships vary from simple error offsets calculated at different levels of the required measurement like different temperature points for a thermocouple thermometer to a slope and intercept correction algorithm in a digital volt meter to very complicated polynomials such as those used for characterizing reference standard radiation thermometers the “as left” verification step is required any time an instrument is adjusted to ensure the adjustment works correctly artifact instruments are measured “asis” since they can’t be adjusted so “as found” and “as left” steps don’t apply a calibration professional performs a calibration by using a calibrated reference standard of known uncertainty by virtue of the calibration traceability pyramid to compare with a device under test he or she records the readings from the device under test and compares them to the readings from the reference source he or she may then make adjustments to correct the device under test calibration example a drywell calibrator fluke 9190a with reference and dut thermometer probes let’s say that you use a precise thermometer to control the temperature in your pharmaceutical plant processes and you need to calibrate it regularly to ensure that your products are created within specified temperature ranges you could send your thermometer to a calibration lab or perform the calibration yourself by purchasing a temperature calibrator such as a liquid bath calibrator or drywell calibrator  a liquidbath calibrator like the fluke calibration models 6109a or 7109a portable calibration baths will have a temperaturecontrolled tank filled with a calibration fluid connected to a calibrated temperature display the drywell calibrator is similar but a metal temperaturecontrolled block will have measurement wells that are sized to fit the diameter of the dut thermometer the calibrator has been calibrated to a known accuracy you place your thermometer the device under test dut in the calibrator tank or measurement well then you note the difference between the calibrator display and the dut over a distributed set of temperatures within the range for which your thermometer is used in this way you verify if your thermometer is within specification or not if the thermometer needs to be adjusted you may be able to adjust the display of the thermometer if it has one or you can use the calibration results to determine new offsets or characterization values for the probe if you make adjustments then the calibration process is repeated to ensure the adjustments worked correctly and verify that the thermometer is within specification you can also use the calibrator to occasionally check the thermometer to make sure its still in tolerance this same general process can be used for many different measurement devices like pressure gauges volt meters etc resources how to calibrate an rtd or platinum resistance thermometer prt  application note by fluke calibration how to calibrate a thermocouple  application note by fluke calibration tools to financially justify calibration equipment  ondemand webinar by fluke calibration why is calibration important calibration helps keep your world up running and safe though most never realize it thousands of calibrations are quietly conducted every day around the world for your benefit when on your next flight or taking medication or passing a nuclear facility you can expect that the systems and processes used to create and maintain them are calibrated regularly to prevent failure both in production and in ongoing use also as discussed above calibration fosters or improves scientific discovery industrial manufacturing and international trade to further appreciate the role precise measurements and calibration play in your life watch this threeminute video by fluke chief metrologist jeff gust made to help commemorate world metrology day which occurs on may 20 of each year the video helps demonstrate how precise measurements impact your daily life in transportation this video is either unavailable or not supported in this browser error code mediaerrsrcnotsupportedtechnical details  no compatible source was found for this media session id 201804119f5bd0b82c8d00c9892a8ec5 player element id vjsvideo3oktest and measurement devices need to be calibrated test  measurement device left being calibrated by a calibrator righttest and measurement devices must be calibrated regularly to ensure they continue to perform their jobs properly safety and compliance with industry standards such as those enforced by the fda in the united states are obvious reasons for keeping test and measurement tools calibrated however as technology demands increase and manufacturing costs go up higher precision tests and measurements are moving from the calibration laboratory and onto the factory floor test and measurement devices that were manufactured within specifications can deteriorate over time due to age heat weathering corrosion exposure to electronic surges accidental damage and more even the best test and measurement instruments can possess manufacturing imperfections random noise and longterm drift that can cause measurement errors these errors such as being off a few millivolts or degrees can be propagated to products or processes being tested with the potential to falsely reject a good unit or result or to falsely accept a bad unit or result ensuring that test and measurement equipment is of sufficient accuracy to verify product or process specifications is necessary to trust and build on the results of scientific experiments ensure the correct manufacture of goods or products and conduct fair trade across country borders calibrators need to be calibrated too a calibrator of lower uncertainty bottom right calibrating a calibrator of higher uncertainty top right automated via calibration software lefta calibrator can drift or wear from calibration tolerances over time and needs to be calibrated on a regular basis usually following the minimum 41 ratio rule calibrators are calibrated regularly by more accurate reference standards this process continues all the way up the calibration traceability pyramid to the most accurate calibration standards maintained by a national metrology institute calibration roiperiodic calibration is usually viewed as a smart business investment with high return on investment roi calibration eliminates waste in production such as recalls required by producing things outside of design tolerances calibration also helps identify and repair or replace manufacturing system components before they fail avoiding costly downtime in a factory calibration prevents both the hard and soft costs of distributing faulty products to consumers with calibration costs go down while safety and quality go up it’s important to point out that both the accuracy and cost of calibration normally declines as you move down the calibration pyramid lower level accuracies may be needed on a manufacturing floor as opposed to those in a primary lab roi is maximized by choosing calibration that matches the accuracy needed resources metrology in daily life  video by vsl the national metrology institute of the netherlands why calibrate test equipment  application note by fluke calibration why measurements matter  video of speech by fluke chief metrologist jeff gust why calibrate  animated video by the u s navy dated but still informative  relevantfluke instruments keep ferry electronics shipshape  metrology case study by fluke a world without metrology  video by vsl the national metrology institute of the netherlands world metrology day resource center  resource center by fluke calibration where are calibrations performed a calibration lab calibrations are commonly performed at national metrology institutes primary calibration labs secondary calibration labs and in the field at places like a manufacturer’s plant floor note that primary and secondary calibration labs can be owned and operated by an independent calibration service provider a calibration company that manufactures calibration instruments like fluke calibration or a manufacturer who performs calibrations in house when are calibrations performed there is no onesizefitsall calibration schedule depending on how frequently you use your equipment and the accuracy required you may need to calibrate as frequently as every month to as infrequently as every year or longer generally the more critical measurements being performed the more frequently you will calibrate if you accidently dropped or otherwise damaged an instrument you will likely want to calibrate it as soon as possible in the test and measurement industry regularly calibrating is important to ensure uniformity of all testing and measurement equipment who performs calibrations people who perform calibration in laboratories include metrologists lab managers calibration engineers calibration technicians people who perform calibration work in the field include manufacturing engineers instrument technicians calibration salaries for information on annual salaries earned by people in the calibration industry see our calibration and metrology compensation survey results get more calibration information not subscribed yet join the fluke calibration email list – see the benefits of subscribing here 