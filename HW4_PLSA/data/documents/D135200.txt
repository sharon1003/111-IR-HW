infrastructure monitoring for everyone ¶overview ¶monitoring refers to the practice of collecting regular data regarding your infrastructure in order to provide alerts both of unplanned downtime network intrusion and resource saturation monitoring also makes operational practices auditable which is useful in forensic investigations and for determining the root cause of errors monitoring provides the basis for the objective analysis of systems administration practices and it in general collecting these data presents its own set of technological problems and general purpose monitoring tools require a great deal of customization and configuration for most uses at the same time most specialized monitoring tools only collect certain types of data and must integrate into general purpose systems there are no easy answers to these issues this document provides an overview of the monitoring problem domain and an introduction to the core strategies and technologies after reading this document i hope that you will have a reasonable understanding of the most important issues and concerns that face monitoring administrators and users background ¶monitoring applications and services are similar to other kinds of services and application in terms of reliability and redundancy requirements see “ high er availability is a hoax ” for more background on the trade offs between availability performance cost and operational requirements in some cases a highly available highly responsive monitoring system to track key production systems is absolutely required but often monitoring systems have less significant requirements at the core monitoring systems are simple tools that collect data generated by or collected from an existing system monitoring tools also include some analytic layer that condenses and correlates data monitoring and alerting are often addressed together because using the data collected by monitoring systems is one of the core applications of monitoring fundamentally collecting and aggregating monitoring data is easy interpreting the data and using monitoring systems is a much more complex and difficult project monitoring systems have two general methods for collecting data “ passive systems ” where monitoring tools observe data created by the application and system under normal operation ie logfiles output or messages from the application itself by contrast “ active systems use agents and tools that capture data or through a monitoring module integrated into the production system itself there advantages and disadvantages to both passive and active monitoring methods and the kind of monitoring tools and data collection method you choose is very highly dependent upon the applications and environment active in your deployment the specific needs use patterns and operational requirements this is true of most systems administration problems to some degree but it is particularly true of monitoring systems key concepts ¶consider the following concepts in monitoring administrationactive monitoring monitoring systems that collect data by directly interacting with the monitored systems administrators must consider the impact ie cost of the monitoring and weigh this with the value of the test itself for example agent that tests the response time on a production database system are typically active testsalert a notification regarding an event captured by a monitoring system produced when a data stream exceeds a preconfigured threshold alerts are often very configurable and allow a variety of operational configurations monitoring systems can send alerts to different tiers of administrators and various thresholds can trigger different kinds of alertsfalse negative an event or alert that a monitoring system fails to detect tests that are not sensitive enough to deceit possible errors and tests which do not run at the right interval or that detect errors of short duration cause these errors false negatives are very serious and significantly impact the utility of a monitoring systemfalse positive an event or alert that lies beyond the monitoring threshold but does not indicate that there is an operational issue monitoring infrastructure that is too sensitive or improperly configured causes these kinds of errors not only are false positives annoying they decrease the effectiveness of other alerts because users are more likely to dismiss alerts that are true positives at the same time false negatives are a far more serious monitoring errorhybrid monitoring there are a class of monitoring collectors that fall somewhere between an active and passive tools particularly depending on your perspective icmp pings or sample page loads might fall into this category but many may feel strongly that these hybrid methods are either active or passive the final distinction is not particularly significantpassive monitoring monitoring systems that collect data by reading data already generated by the monitored system the system collects this data from logs”traps” or from messages sent by the monitored system to a passive data collection agent the “ syslog system is an example of passive monitoring passive monitoring is significantly less resource intensive for the monitored system than other methodssyslog refers the standard logging format that originated with early bsd unix utilities ie sendmail and was later made generic for tool all system logging a number of additional tools adopted the syslog format for reporting and log analysis and has is now a standard these days syslog is rather poorly utilized despite its ubiquity with many applications using their own logging systems or using the syslog and the syslog format in ways that go beyond the standard and intention of the systemthreshold a configured setting outside of which administrators expect that a system cannot function thresholds must be “tuned” to prevent false positives or false negatives deploying monitoring ¶monitoring infrastructure shouldrun as distinctly as possible from production servicesnot create a significant impact on the system that it’s monitoring failure of the monitored system should not cause a failure in the monitoring system simple redundancy and automatic failover is particularly important for monitoring systems as it is important to “monitor the monitoring” or ensure that an inoperative monitoring system doesn’t generate false positives see also“ higher availability ”infrastructure and architectures ¶monitoring systems often consist of a central monitoring server that collects and aggregates the data from a series of agent or “probe” systems that are part of the monitoring infrastructure these agents collect the data from the monitored system and allow for a layer of redundancy and operational flexibility within the monitoring system agents make it possible to provide reasonable distributed scale for monitoring systems monitoring infrastructure require redundancy and backup considerations if you use your monitoring system for uptime monitoring and the monitoring system goes down it’s impossible to know what services are accessible for transient outages this isn’t a problem but for longer sitewide infrastructure having this level of monitoring is essential in some cases reporting requirements demand “secondary” monitoring systems that fully replicate primary monitoring more often you can have just enough infrastructure to ensure that the primary monitoring node and other essential services are up while retaining the core monitoring on primary some kinds of distributed architectures may also provide a necessary level of redundancy rather than centralize all monitoring aggregation have a collection of “probes” feed data into local collectors and data processing systems that do most of the work on a persite basis while one or two “master systems” aggregate the data sitecollectors can be redundant at whatever level your operational guidelines require as with all systems architecture additional systems add complexity which increases the chance of failure tiered and distributed approaches to deploying systems and solutions are often the most robust and reliable but they are the most difficult to configure and prone to error while a distributed system may seem to solve most of your redundancy and recursive monitoring needs there are enough hidden risks and complexities to indicate avoiding this kind of deployment unless absolutely necessary alerts and notifications ¶alerts and notifications are the core uses of monitoring infrastructure and likely the first or second service that you should configure in a new monitoring system in most cases you can summarize an alert as “ when this metric passes outside of these boundaries make sure an administrator knows about it ” however in practice there are many concerns and conditions that affect alert logic and behavior consider the following conditions and features escalation it’s not enough to simply send alerts you need to ensure that someone acknowledges the alert and handles the recovery since people have “real lives” and aren’t always on call you need to be able to send alert to someone on the front lines and if they cannot respond pass that alert onto someone else in some cases it’s possible to “fake” escalation with two alerts send one message every minute if the system has been down for five minutes and one message every minute if the system has been down for more than fifteen minutes this gives the frontline engineer ten minutes to disable the alert or fix the system before “waking someone else up” in most cases the second person will never get called high “signal to noise” ratio it’s possible to turn on alerts for many different metrics but this has the effect of “spamming” administrators and decreasing the relative perceived importance of any given alert if every alert that an oncall administrator receives is not crucial and actionable then the system is broken some sort of oncall automation most systems have more than one administrator and have some sort of administrator duty compatible with multiple contact methods in many cases email is the linguafranca for alert systems it provides compatibility with sms and blackberrysmartphones and is incredibly portable you must consider the delay between sending an alert and an administrator receiving and being able to respond to that alert when choosing alert methods it’s useful to be able to configure logic when and where to send alerts on a peruser basis configurable realerting depending on the service that the alert “covers” an alert may need to resent after a certain period of time if the metric remains outside of the threshold when deploying alerts consult with administrators on error responses handling strategies and average recovery times ideally alerts will be able to cover their systems such that administrators will have no need to routinely “check” a system covered by an alert monitoring tools ¶this section identifies the leading open source monitoring tools and attempts to catalog their functionality and purpose if you have infrastructure that you need to monitor you should be familiar with these tools cacti cacti is a network traffic monitoring tool built on top of rrd while cacti is primarily used for collecting network utilization data it can accept data by way of the snmp protocol cacti focuses on collecting a large amount of data from a large number of hosts and aggregating that data into a single coherent interface cacti thus is a data collection and aggregation framework monit monit monitors and supervises specific processes for unix and linux systems where other tools can provide data to answer a variety of different kinds of questions monit simply answers the question “is this process up” monit works by directly spawning as the init process does on most unix systems the processes that it monitors and is not distributed in normal operation such “ uptime monitoring ” is a very useful part of any deployment but for critical infrastructure it’s important to collect additional data and monitor for additional infrastructure concerns ie capacity and utilization as well as larger trends and correlations munin munin is a resource monitoring and data collection tool it uses rrd to store and graph data munin can collect and display data from any kind of unix or unixlike host including mac os x and linux munin has no concept of “ threshold ” or “ alert ” but can interact with other systems to provide this functionality munin operates with a “master” daemon that runs on one system and data collection nodes that must run on the monitored system while the “master” node only needs to run on one system in an environment all monitored systems must run the “muninnode” process nagios nagios a generic monitoring framework that provides a sophisticated alert notification and data collection framework with an extensive plugin framework it’s possible to use nagios to monitor virtually any kind of system or operation using either passive or active techniques nagios has a primary monitoring node that collects data from other agents and processes that run in a more distributed manner when choosing or deploying a monitoring solution consider the following factors how does the platform collect data and what impact does this collection method have on the performance of the monitored system how many systems can the solution monitor and what kinds of resources does the tool require to support this level of service how much logical physical andor network separation can the monitoring application get from the monitored application can the platform provide alerts and notifications or must it integrate with another solution what monitors the monitoring system what kinds of issues and errors will the solution detect and what kinds of situations is the solution unable to detect  network related problems for instance are extremely difficult to detect and monitor because monitoring applications are themselves network dependent to some degree appliances and hosted services ¶as in many domains its possible to outsource monitoring to vendors who provide monitoring solutions as hosted services or as dropplugin appliances while there are advantages and disadvantages to these and to conventional monitoring tools outsourcing and “appliances” both release administrators from the additional burden of monitoring administering infrastructure and makes a certain amount of operational sense it makes sense to outsource monitoring for a number of reasons includingmonitoring is mission critical and if you’re working in a smaller organization you’re probably not at expert at deploying monitoring tools and you’re not in the business of monitoring probably monitoring systems ought to be distinct from the systems that they monitor this allows the monitoring to remain operational throughout various service interruptions this separation ought to cover both the actual infrastructure and the operation and maintenance of the production and monitoring systemsdoing monitoring right on your own can be quite expensive because the actual hardware reliability and data processing requirements are high and a specialized monitoring vendor can often provide these services at great discount in price and time feedback loops ¶technically speaking installing configuring and tuning monitoring to report useful information is a huge challenge while some nonsystems administrators can make use of monitoring technologies in various contexts 1 unlike most applications that systems administrators must deploy and maintain monitoring systems’ primary users are systems administrators figuring out how to use monitoring systems to better administer a group of systems monitoring makes it possible for a smaller number of systems administrators to administer a greater number of systems 2 this section focuses on major applications for monitoring data both in the automation of infrastructure and the analysis of data regarding that infrastructure 1 alerts and notifications of various events have a number of different applications collected data can help justify budgets to people who aren’t involved in the administration ie “business leaders” 2 efficiency in systems administration almost never results in a decrease of employment for actual systems administrators but rather an ability for the existing or a modestly expanded workforce to manage to expanded demands from business and developer units automation ¶with the advent of cloud computing and automation surrounding virtualization the use of monitoring solutions to underpin infrastructure deployment and management the theory is in essence that as utilization varies between thresholds additional capacity is automatically added and removed for example if your application servers can effectively handle 1000 requests a second you could trigger the following actions using data polled every 5 or 10 minutes add a node to the cluster when the average load equals 800 requests per second remove a node from the cluster when the average load equals 400 requests per second set a node to “not accept” new connections in the load balancer if it has more than 1100 connections per second alert if more than 48 application servers are running on any given instance to log and restartredeploy application servers that have frozen or are no longer running to never remove an instance if there are fewer than three nodes to notify administrators and escalate if the automated system adds more than three nodes within an hour say or four nodes within 2 hours to prevent runaway costs and malicious traffic floods the truth is however that this is a poor example application servers are easy to relate but the truth is that most administrators will be able to have long and busy careers for successful clients and never have a situation where they’ll need to use more than 612 application servers or need to deploy new application servers more than once a week in most cases traffic is predictable enough that “autoscaling” requires too much additional machinery for a relatively infrequent problem nevertheless there are parts of the above example that are useful for automating various kinds of capacity planning establish thresholds and alerts to detect when there is too much excess capacity as well as insufficient capacity it’s easy to scale up in response to additional load but comparatively difficult to scale down scaling down is the part of automation that actually saves money have the monitoring system tweak the load balancing settings if a node looks like it’s in trouble or might become saturated start moving traffic away from it until blocking tasks complete and it has additional capacity this kind of tweaking is inefficient if you’re a human because it amounts to endless “knob twiddling” but can be useful when automated ensure that changes in capacity happen gracefully add additional capacity before you need it and remove capacity after you’re sure that you no longer need it to maintain the current service level the process of developing automation around monitoring evolves from the same process as tuning and deploying alerts while there are some detectable events that require human intervention you can automate most human responses to any given alert keep track of how you and your team resolves alerts and then attempt to automate these tasks as much as possible note for a lot of capacitythroughput related tasks often it’s more ideal maintain specific statefull infrastructure for data persistence ie databases message busqueuing systems and automated tasks but then do all “work” of the application layer in completely stateless systems “hanging” off of the message queue or queues examples of this may be media transcoding for a image or video gallery or catalog andor order management for an ecommerce site queues keep application logic simple while reducing the need for statefull systems and synchronous operation obviously however this is a fundamental application design problem and something that’s outside of the bounds of systems administration in that light while the above “autoscaling” script seems frightful in many cases administrators will have to developed solutions like this in situations where developers could improve software analytics ¶monitoring systems are really just big data collection and aggregation frameworks it’s important to have monitoring to track capacity usage and problems that can cause downtime so that administrators can attend to these issues however when you have a system for collecting data and performing analysis there are other kinds of analysis that become quite easy for example you mayfigure out what areas or aspect of the system produces errors or experiences poor performance then you can pass these messages as reports to the development teams by integrating more closely engineering with teams you can probably collect even more useful dataidentify trends in network usage and independently verify your providers’ services particularly in a comparative context this allows you to enter into contracts with more information and negotiate from a place of powercorrelate certain use patterns with each other particularly regarding different aspects of a product use these data to suggest integration “higher up” in the engineering process systems administrations are often primarily responsible for larger portions of a product that developers and can provide valuable feedback to engineering teams monitoring requirements ¶consider the following set of minimum operational requirements for a functioning monitoring system monitor everything if it’s not important enough to monitor the service or resource may not be providing value monitor monitoring systems themselves use different kinds of tests and tools to collect data to prevent measurement errors ensure that alerts are useful and actionable by administrators expect to spend time tuning and modifying monitoring frequency so that you’re not collecting too much data or archiving data without these features a monitoring system may not be worth the resources that it consumes