siri google assistant and alexa hacked with high frequency dolphin attack bret kinsella on september 6 2017 at 858 am tweet share share researchers out of china have demonstrated a security flaw that is apparently common across voice assistants fast company reports that chinese researcher have shown that translating voice commands into ultrasonic frequencies inaudible to humans are easily recognized by voice assistants this means “hey siri” “ok google” or “alexa” could all be uttered by a machine and wake up your i phone google home or echo respectively subsequent inaudible commands could be issued to the activated voice assistants and execute tasks such as making a phone call visiting a website or controlling smart home devices the video below demonstrates what is called a dolphin attack an i phone is first shown to make a call using audible voice commands issued to siri then the i phone is shown to be locked and an inaudible voice command in an ultrasonic range is issued to siri which then recognizes the command and again makes a call this would be without the knowledge of device owner if they weren’t looking at the screen dolphin attack inaudible voice command your browser does not currently recognize any of the video formats available click here to visit our frequently asked questions about html5 video000  043what this means for voice assistant security the successful dolphin attack raises several concerns unlike the previous demonstration hack on the amazon echo that attack could only be achieved with physical access to the device so really was an issue of physical security and was only effective on older devices the dophin attack works on current devices and across a range of voice assistants however there are practical limitations distance noise command type and device use are mitigating factors the report differentiated between activation and recognition activation was whether the wake word or phrase made the voice assistant ready for a command recognition was whether it could interpret a command and execute a task after being activated both activation and recognition are required for an attack to be successful these two factors were impacted significantly by distance and background noise effective range for attacks in terms of distance was between 2 cm 08 inches and 175 cm 5 feet amazon echo was the most susceptible to longrange attacks which was expected given the engineering behind its farfield microphones interestingly older i phone models like the 4s also had substantial farfield recognition capabilities nearly rivaling amazon echo by contrast newer i phone models like the 6s and 7 were only accessible in the near field of 12 cm or less and the 6s plus would not recognize the commands the attacking device must be in near proximity to your device for this to have a chance to work background noise also played a big factor a quiet office setting yielded consistent attack success rates while the louder “cafe” and “street” settings became harder with 80 and 30 success rates respectively the type of commands also matter “open” and “call” were harder to successfully execute than “turn on airplane mode” and “how is the weather” that was impacted by the requirement for the recognition to have near perfect accuracy for web addresses or phone numbers to be successful finally this only works surreptitiously if the device owner is not currently using the device and it is not visible otherwise the attack would become noticed by the device owner preventing dophin attacks on voice assistants the report goes on to suggest manufacturers make some hardware alterations to address this vulnerability the root cause of inaudible voice commands is that microphones can sense acoustic sounds with a frequency higher than 20 k hz while an ideal microphone should not…thus a microphone shall be enhanced and designed to suppress any acoustic signals whose frequencies are in the ultrasound range for instance the microphone of i phone 6 plus can resist to inaudible voice commands well there is also a software based solution that the research called out using google assistant as an example the original signal is produced by the google tts engine the carrier frequency for modulation is 25 k hz thus we can detect dolphin attack by analyzing the signal in the frequency range from 500 to 1000 hz in particular a machine learning based classifier shall detect it this could also be addressed by voice fingerprinting technology similar to what google home uses today to differentiate users that would require an attacker to have a voice recording of the device owners voice to carry out an exploit what is means for users today from a practical standpoint few users should fear a dolphin attack today the attacker needs to be in near proximity know the device you are using and be in an environment with little background noise however the researchers have performed a great service in bringing this issue to light now and offering practical suggestions for manufacturers to patch this vulnerability as voice assistants become more commonly used they will draw attention from cyber attackers that means there will be many more potential exploits that will require patches welcome to the world of software follow bretkinsella amazon alexa now recommends third party skills google home can now distinguish multiple users by voice tweet share share categories amazon alexa apple siri devices google home voice security tagged alexa google assistant siri voice assistant security voice security2bret kinsella previous article amazon now allows alexa skills for kids next article apple air pods account for 85 percent of wireless headphone sales in 2017 so far subscribe to voicebot weekly first name email subscribetweets over half of smartphone owners use voice assistants siri leads the pack httpstconh lv egnqpl bretkinsellavoicebotai 13 hours ago google home now available in italy bretkinsella httpstcoc pfs bi50h0voicebotai 19 hours ago use amazon alexa for donations to 48 charities by voice httpstcomrmx wmp xzj bretkinsellavoicebotai 1 day ago smart speaker owners use voice assistants nearly 3 times per day httpstcop2t96c tina bretkinsellavoicebotai 1 day ago volley cofounders max child and james wilsterman interview – voicebot podcast episode 36 httpstcoo fd0uis0m5 … httpstcofgvznh npy wvoicebotai 1 day ago latest posts over half of smartphone owners use voice assistants siri leads the pack ai3 apr 1google home now available in italy devices3 apr 1volley cofounders max child and james wilsterman interview – voicebot podcast episode 36alexa skills2 apr 1